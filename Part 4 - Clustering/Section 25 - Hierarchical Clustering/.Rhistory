getwd()
contohArray = c(1,1,2,3,5,8)
ls()
plot(contohArray)
plot(contohArray, type="l")
plot(contohArray, type="h")
plot(contohArray, type="s")
attach(mtcars)
plot(wt, mpg)
abline(lm(mpg~wt))
title("Regression of MPG on Weight")
require(stats)
plot(cars)
lines(lowess(cars))
plot(sin, -pi, 2*pi)
plot(table(rpois(100,5)), type="h", col="red", lwd=10, main = "rpois(100, lambda=5)")
plot(x <- sort(rnorm(47)), type = "s", main = "plot(x, type = \"s\")")
points(x,cex=.5, col = "dark red")
print(contohArray)
barplot(contohArray, col="darkgreen")
x <- c(7,6,8,5,9,9.5,8.3,7.5)
ls
ls()
y <- c(1.2,1.7,1.5,1.3,1.0,1.4,0.8,1.1)
print(x)
bagus_x <- c(7,8,9,9.5)
bagus_y <- c(1.7,1.3,0.8)
test_x <-(7.5)
test_7 <-(1.1)
test_y <-(1.1)
print(test_x)
print(x)
cls
cls()
print(bagus_x)
ls()
install.packages('devtools')
install.packages('keras')
exit
exit()
#listing program 4.1 latihan produk k-NN dengan R
x <- c(7,6,8,5,9,9.5,8.3,7.5)
y <- c(1.2,1.7,1.5,1.3,1.0,1.4,0.8,1.1)
bagus_x <- c(7,8,9,9.5)
bagus_y <- c(1.2, 1.5, 1.0, 1.4)
test_x <- (7.5)
test_x <- (7.5)
test_y <- (1.1)
merk_bagus <- c('A','C','E','F')
merk_kurang <- c('B','D','G')
merk_test <- c('H')
setwd("D:/Rizky's File/Tutorial/Udemy/Data Science/Machine Learning A-Z/Part 4 - Clustering/Section 25 - Hierarchical Clustering")
dataset = read.csv('Mall_Customer.csv')
dataset = read.csv('Mall_Customers.csv')
View(dataset)
View(dataset)
X = dataset[4:5]
View(X)
View(X)
# Using the dendogram to find the optimal number of cluster
dendogram = hclust(dist(X, method = 'euclidean'),
method = 'word.D')
# ploting the dendogram
plot(dendogram,
main = paste('Dendogram'),
xlab = 'Customer',
ylab = 'Euclidean distance')
# Using the dendogram to find the optimal number of cluster
dendogram = hclust(dist(X, method = 'euclidean'),
method = 'word.D')
# Using the dendogram to find the optimal number of cluster
dendogram = hclust(dist(X, method = 'euclidean'),
method = 'ward.D')
# ploting the dendogram
plot(dendogram,
main = paste('Dendogram'),
xlab = 'Customer',
ylab = 'Euclidean distance')
# Fitting Hierarchical Clustering to the mall dataset
hc = hclust(dist(X, method = 'euclidean'),
method = 'word.D')
y_hc = cutree(hc, 5)
# Visualising the Cluster
library(cluster)
clusplot(X,
y_hc$cluster,
lines = 0,
shade = TRUE,
color = TRUE,
plotchar = FALSE,
span = TRUE,
main = paste("Cluster of clients"),
xlab = "Anual Income",
ylab = "Spending Score")
# Fitting Hierarchical Clustering to the mall dataset
hc = hclust(dist(X, method = 'euclidean'),
method = 'word.D')
y_hc = cutree(hc, 5)
# Fitting Hierarchical Clustering to the mall dataset
hc = hclust(dist(X, method = 'euclidean'),
method = 'ward.D')
y_hc = cutree(hc, 5)
# Visualising the Cluster
library(cluster)
clusplot(X,
y_hc$cluster,
lines = 0,
shade = TRUE,
color = TRUE,
plotchar = FALSE,
span = TRUE,
main = paste("Cluster of clients"),
xlab = "Anual Income",
ylab = "Spending Score")
# Visualising the Cluster
library(cluster)
clusplot(X,
y_hc,
lines = 0,
shade = TRUE,
color = TRUE,
plotchar = FALSE,
span = TRUE,
main = paste("Cluster of clients"),
xlab = "Anual Income",
ylab = "Spending Score")
